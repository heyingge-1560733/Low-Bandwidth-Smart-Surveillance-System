{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyGX4hRSHU1d"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook helps to create a training set for the k-NN classifier described in the MediaPipe [Pose Classification](https://google.github.io/mediapipe/solutions/pose_classification.html) soultion, export it to a CSV and then use it in the [ML Kit sample app](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgHTsKdz7cn_"
   },
   "source": [
    "# Step 1: Upload image samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BfvGuy37ih1"
   },
   "source": [
    "Locally create a folder named `poses_images_in` with image samples.\n",
    "\n",
    "Images should repesent terminal states of desired pose classes. I.e. if you want to classify burglary provide images for two classes: burglary and normal.\n",
    "\n",
    "There should be about a few hundred samples per class covering different camera angles, environment conditions, body shapes, and exercise variations to build a good classifier.\n",
    "\n",
    "Required structure of the images_in_folder:\n",
    "```\n",
    "poses_images_in/\n",
    "  burglary/\n",
    "    image_001.jpg\n",
    "    image_002.jpg\n",
    "    ...\n",
    "  normal/\n",
    "    image_001.jpg\n",
    "    image_002.jpg\n",
    "    ...\n",
    "  ...\n",
    "```\n",
    "\n",
    "Zip the `poses_images_in` folder:\n",
    "```\n",
    "zip -r poses_images_in.zip poses_images_in\n",
    "```\n",
    "\n",
    "And run the code below to upload it to the Colab runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdtsJ8TvqktY"
   },
   "source": [
    "# Step 2: Create samples for classifier\n",
    "\n",
    "Runs BlazePose on provided images to get target poses for the classifier in a format required by classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/freddie/Music\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/freddie/Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7PiV3r_Pphln"
   },
   "outputs": [],
   "source": [
    "# Folder with images to use as target poses for classification.\n",
    "#\n",
    "# Images should repesent terminal states of desired pose classes. I.e. if you\n",
    "# want to classify burglary provide iamges for two classes: burglary and normal\n",
    "#\n",
    "# Required structure of the images_in_folder:\n",
    "#   poses_images_in/\n",
    "#     pose_class_1/\n",
    "#       image_001.jpg\n",
    "#       image_002.jpg\n",
    "#       ...\n",
    "#     pose_class_2/\n",
    "#       image_001.jpg\n",
    "#       image_002.jpg\n",
    "#       ...\n",
    "#     ...\n",
    "images_in_folder = 'poses_images_in'\n",
    "\n",
    "# Output folders for bootstrapped images and CSVs. Image will have a predicted\n",
    "# Pose rendering and can be used to remove unwanted samples.\n",
    "images_out_folder = 'poses_images_out'\n",
    "\n",
    "# Output CSV path to put bootstrapped poses to. This CSV will be used by the\n",
    "# demo App.\n",
    "#\n",
    "# Output CSV format:\n",
    "#   poses_images_in/\n",
    "#     pose_class_1/\n",
    "#       sample_00001,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
    "#       sample_00002,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
    "#       ...\n",
    "#     pose_class_2/\n",
    "#       sample_00001,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
    "#       sample_00002,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
    "#       ...\n",
    "#   ...\n",
    "#\n",
    "csvs_out_folder = 'poses_csvs_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "btboitEDrSDq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping  burglary\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\n",
      "Bootstrapping  normal\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "\n",
    "# Folder names are used as pose class names.\n",
    "pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "\n",
    "for pose_class_name in pose_class_names:\n",
    "  print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
    "\n",
    "  if not os.path.exists(csvs_out_folder):\n",
    "    os.makedirs(csvs_out_folder)\n",
    "    \n",
    "  with open(os.path.join(csvs_out_folder,pose_class_name+'.csv'), 'w') as csv_out_file:\n",
    "    csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    if not os.path.exists(os.path.join(images_out_folder, pose_class_name)):\n",
    "      os.makedirs(os.path.join(images_out_folder, pose_class_name))\n",
    "\n",
    "    image_names = sorted([\n",
    "        n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
    "        if not n.startswith('.')])\n",
    "    for image_name in tqdm.tqdm(image_names, position=0):\n",
    "      # Load image.\n",
    "      input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
    "      input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      # Initialize fresh pose tracker and run it.\n",
    "      with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose_tracker:\n",
    "        result = pose_tracker.process(image=input_frame)\n",
    "        pose_landmarks = result.pose_landmarks\n",
    "      \n",
    "      # Save image with pose prediction (if pose was detected).\n",
    "      output_frame = input_frame.copy()\n",
    "      if pose_landmarks is not None:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=output_frame,\n",
    "            landmark_list=pose_landmarks,\n",
    "            connections=mp_pose.POSE_CONNECTIONS)\n",
    "      output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "      cv2.imwrite(os.path.join(images_out_folder, pose_class_name, image_name), output_frame)\n",
    "      \n",
    "      # Save landmarks.\n",
    "      if pose_landmarks is not None:\n",
    "        # Check the number of landmarks and take pose landmarks.\n",
    "        assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "        pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "        # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "        # correct aspect ratio.\n",
    "        frame_height, frame_width = output_frame.shape[:2]\n",
    "        pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "        # Write pose sample to CSV.\n",
    "        pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.str).tolist()\n",
    "        csv_out_writer.writerow([image_name] + pose_landmarks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfD86A2d1-8j"
   },
   "source": [
    "Now look at the output images with predicted Pose and remove those you are not satisfied with from the output CSV. Wrongly predicted poses will affect accuracy of the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Manual filtration\n",
    "\n",
    "Please manually verify predictions and remove samples (images) that has wrong pose prediction. Check as if you were asked to classify pose just from predicted landmarks. If you can't - remove it.\n",
    "\n",
    "Align CSVs and image folders once you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def align_images_and_csvs(print_removed_items=False):\n",
    "    \"\"\"Makes sure that image folders and CSVs have the same sample.\n",
    "    \n",
    "    Leaves only intersetion of samples in both image folders and CSVs.\n",
    "    \"\"\"\n",
    "    for pose_class_name in pose_class_names:\n",
    "      # Paths for the pose class.\n",
    "      images_out_pose_folder = os.path.join(images_out_folder, pose_class_name)\n",
    "      csv_out_path = os.path.join(csvs_out_folder, pose_class_name + '.csv')\n",
    "\n",
    "      # Read CSV into memory.\n",
    "      rows = []\n",
    "      with open(csv_out_path) as csv_out_file:\n",
    "        csv_out_reader = csv.reader(csv_out_file, delimiter=',')\n",
    "        for row in csv_out_reader:\n",
    "          rows.append(row)\n",
    "            # Image names left in CSV.\n",
    "      image_names_in_csv = []\n",
    "\n",
    "      # Re-write the CSV removing lines without corresponding images.\n",
    "      with open(csv_out_path, 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in rows:\n",
    "          image_name = row[0]\n",
    "          image_path = os.path.join(images_out_pose_folder, image_name)\n",
    "          if os.path.exists(image_path):\n",
    "            image_names_in_csv.append(image_name)\n",
    "            csv_out_writer.writerow(row)\n",
    "          elif print_removed_items:\n",
    "            print('Removed image from CSV: ', image_path)\n",
    "\n",
    "      # Remove images without corresponding line in CSV.\n",
    "      for image_name in os.listdir(images_out_pose_folder):\n",
    "        if image_name not in image_names_in_csv:\n",
    "          image_path = os.path.join(images_out_pose_folder, image_name)\n",
    "          os.remove(image_path)\n",
    "          if print_removed_items:\n",
    "            print('Removed image from folder: ', image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_images_and_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "Pose classification (basic).ipynb",
   "provenance": [
    {
     "file_id": "1z4IM8kG6ipHN6keadjD-F6vMiIIgViKK",
     "timestamp": 1651987472922
    },
    {
     "file_id": "1Z9qskXEIk_357JKDfO2vjc3opDjoqzBP",
     "timestamp": 1608072089933
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
